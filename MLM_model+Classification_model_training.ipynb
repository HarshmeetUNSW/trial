{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8878869,"sourceType":"datasetVersion","datasetId":5344005},{"sourceId":8878924,"sourceType":"datasetVersion","datasetId":5344024}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installing necessary Libraries","metadata":{}},{"cell_type":"code","source":"pip install emoji==1.6.1\n","metadata":{"execution":{"iopub.status.busy":"2024-07-07T14:42:28.457954Z","iopub.execute_input":"2024-07-07T14:42:28.458405Z","iopub.status.idle":"2024-07-07T14:42:44.258736Z","shell.execute_reply.started":"2024-07-07T14:42:28.458376Z","shell.execute_reply":"2024-07-07T14:42:44.257555Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting emoji==1.6.1\n  Downloading emoji-1.6.1.tar.gz (170 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.0/170.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for emoji: filename=emoji-1.6.1-py3-none-any.whl size=169295 sha256=ee0f05e91b7818c2c424427b6fa87fdd222afed9f0a870235405362a61dbfa89\n  Stored in directory: /root/.cache/pip/wheels/3d/c9/af/02caa5725634f27f4e2e43852f67fc9069d014038b236a827e\nSuccessfully built emoji\nInstalling collected packages: emoji\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.12.1\n    Uninstalling emoji-2.12.1:\n      Successfully uninstalled emoji-2.12.1\nSuccessfully installed emoji-1.6.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# All the necessary imports","metadata":{}},{"cell_type":"code","source":"\nimport json\nimport emoji\nfrom collections import Counter\nimport pandas as pd\nimport re\nimport numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport numpy as np","metadata":{"id":"BMvuv7VbQ1Xj","execution":{"iopub.status.busy":"2024-07-07T15:00:47.212602Z","iopub.execute_input":"2024-07-07T15:00:47.213276Z","iopub.status.idle":"2024-07-07T15:00:54.192278Z","shell.execute_reply.started":"2024-07-07T15:00:47.213244Z","shell.execute_reply":"2024-07-07T15:00:54.191442Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n  return _methods._mean(a, axis=axis, dtype=dtype,\n/opt/conda/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n  ret = ret.dtype.type(ret / rcount)\n","output_type":"stream"},{"name":"stdout","text":"{'Jewish', 'Arab', 'Asian', 'None', 'Caucasian', 'Women', 'Islam', 'Refugee', 'African', 'Hispanic', 'Homosexual'}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"## Data Processing\n\nwith open('/kaggle/input/data111/dataset.json', 'r') as file:\n    data = json.load(file)\n\n\n\n## MAKING LABELS\n\n\nFINAL_LABEL_LIST =[]\nfor k in list(data.keys()):\n  # Extract labels\n  label_list = [item['label'] for item in data[k]['annotators']]\n\n  # Count occurrences of each label\n  label_counts = Counter(label_list)\n\n  # Calculate total number of labels\n  total_labels = len(label_list)\n\n  # Determine the label with the highest frequency\n  most_common_label, count = label_counts.most_common(1)[0]\n\n  # Check if the highest frequency label occurs more than 50% of the time\n  if count / total_labels > 0.5:\n      assigned_label = most_common_label\n  else:\n      assigned_label = None\n  FINAL_LABEL_LIST.append(assigned_label)\n\n\nCounter(FINAL_LABEL_LIST)\n\ninput_data= []\nrationales = []\npost_ids=[]\nfor k in list(data.keys()):\n  # print(k)\n  # print(data[k]['rationales'])\n  if k =='24439295_gab':\n    rationales.append([])\n  else:\n    rationales_array = np.array(data[k]['rationales'])\n    averaged_rationales = np.mean(rationales_array, axis=0)\n    averaged_rationales_list = averaged_rationales.tolist()\n    if type(averaged_rationales_list) ==list:\n      finalized_rationales = [1 if value > 0.5 else 0 for value in averaged_rationales_list]\n    else:\n      finalized_rationales =[0]*len(data[k]['post_tokens'])\n\n    rationales.append(finalized_rationales)\n  input_data.append(' '.join(data[k]['post_tokens']))\n  post_ids.append(data[k]['post_id'])\n\nlen(input_data), len(rationales), len(FINAL_LABEL_LIST)\n\n# Sample data\n# Function to process the data\nFINAL_TARGET_LIST = []\ndef get_majority_targets(data):\n    target_count = {}\n    total_entries = len(data)\n\n    # Count the occurrences of each target\n    for entry in data:\n        for target in entry['target']:\n            if target in target_count:\n                target_count[target] += 1\n            else:\n                target_count[target] = 1\n\n    # Determine which targets appear in more than 50% of the entries\n    majority_targets = [target for target, count in target_count.items() if count / total_entries > 0.5]\n\n    return majority_targets\n\nfor k in list(data.keys()):\n  # print(data[k]['annotators'])\n  majority_targets = get_majority_targets(data[k]['annotators'])\n  if majority_targets==[]:\n    majority_targets=['None']\n  FINAL_TARGET_LIST.append(majority_targets)\n\n#print(\"Targets appearing in more than 50% of the entries:\", FINAL_TARGET_LIST)\n\n\ndf= pd.DataFrame()\ndf['post_ids']=post_ids\ndf['input_text']= input_data\ndf['rationales'] = rationales\ndf['label']= FINAL_LABEL_LIST\ndf['Final_target']= FINAL_TARGET_LIST\ndf.head()\n\ndf = df.dropna(subset=['label'])\ndf\n\n# def clean_html_tags_and_update_rationales(row):\n#     \"\"\"Remove HTML-like tags from tokens and update rationales accordingly.\"\"\"\n#     tokens = row['input_text'].split()\n#     rationales = row['rationales']\n#     cleaned_tokens = []\n#     cleaned_rationales = []\n\n#     for token, rationale in zip(tokens, rationales):\n#         if not (token.startswith('<') and token.endswith('>')):\n#             cleaned_tokens.append(token)\n#             cleaned_rationales.append(rationale)\n\n#     # Return a series with updated values\n#     return pd.Series([cleaned_tokens, cleaned_rationales], index=['input_text', 'rationales'])\n\n# # Apply the cleaning function to each row\n# df[['input_text', 'rationales']] = df.apply(clean_html_tags_and_update_rationales, axis=1)\n\n# # Since 'cleaned_input_text' is now a list of tokens, we need to join them back into strings\n# df['input_text'] = df['input_text'].apply(' '.join)\n\n\n# Function to transform labels to toxic non toxic\n# def transform_label(label):\n#     if label == 'normal':\n#         return 'non-toxic'\n#     elif label in ['hatespeech', 'offensive']:\n#         return 'toxic'\n#     else:\n#         return label\n\n# # Apply the transformation\n# df['label'] = df['label'].apply(transform_label)\n\n\n\ndf['label'].value_counts()\n\nfinal_communities_sel = ['African',\n 'Islam',\n 'Jewish',\n 'Homosexual',\n 'Women',\n 'Refugee',\n 'Arab',\n 'Caucasian',\n 'Asian',\n 'Hispanic']\ndf.reset_index(inplace=True, drop=True)\nfinal_target_information =[]\nfor i in range(len(df)) :\n    temp = list(set(df['Final_target'][i])&set(final_communities_sel))\n    if len(temp) == 0:\n        final_target_information.append(['None'])\n    else:\n        final_target_information.append(temp)\ndf['Final_target']=final_target_information\n\n\n\nall_values = []\nfor item in df['Final_target']:\n    if isinstance(item, list):\n        all_values.extend(item)\n    else:\n        all_values.append(item)  # This handles non-list items, just in case\n\n# Get unique values from the list of all values\nunique_values = set(all_values)\n\n# Display the unique values\n# print(unique_values)\n\n# def deemojize_text(text):\n#     return emoji.demojize(text,use_aliases=True)\n# df['input_text'] = df['input_text'].apply(deemojize_text)\n\n# df\n\n# df.to_excel('tiktok_updated4.xlsx')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-07-07T15:00:54.194138Z","iopub.execute_input":"2024-07-07T15:00:54.194596Z","iopub.status.idle":"2024-07-07T15:00:54.215934Z","shell.execute_reply.started":"2024-07-07T15:00:54.194562Z","shell.execute_reply":"2024-07-07T15:00:54.214868Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"                          post_ids  \\\n0      1179055004553900032_twitter   \n1      1179063826874032128_twitter   \n2      1178793830532956161_twitter   \n3      1179088797964763136_twitter   \n4      1179085312976445440_twitter   \n...                            ...   \n19224                  9989999_gab   \n19225                  9990225_gab   \n19226                  9991681_gab   \n19227                  9992513_gab   \n19228                  9998729_gab   \n\n                                              input_text  \\\n0      i dont think im getting my baby them white 9 h...   \n1      we cannot continue calling ourselves feminists...   \n2                          nawt yall niggers ignoring me   \n3      <user> i am bit confused coz chinese ppl can n...   \n4      this bitch in whataburger eating a burger with...   \n...                                                  ...   \n19224  if ur still on twitter tell carlton i said his...   \n19225  when i first got on here and said i hate trump...   \n19226  was macht der moslem wenn der zion gegen seine...   \n19227  it is awful look at world demographics asians ...   \n19228  the jewish globalist elite have only imported ...   \n\n                                              rationales       label  \\\n0      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      normal   \n1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      normal   \n2                                        [0, 0, 0, 0, 0]      normal   \n3      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  hatespeech   \n4      [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  hatespeech   \n...                                                  ...         ...   \n19224  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, ...   offensive   \n19225  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   offensive   \n19226  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...      normal   \n19227  [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...  hatespeech   \n19228  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, ...   offensive   \n\n                   Final_target  \n0                        [None]  \n1                        [None]  \n2                     [African]  \n3                       [Asian]  \n4            [Caucasian, Women]  \n...                         ...  \n19224                    [None]  \n19225                 [African]  \n19226                    [None]  \n19227                   [Asian]  \n19228  [Islam, Jewish, African]  \n\n[19229 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>post_ids</th>\n      <th>input_text</th>\n      <th>rationales</th>\n      <th>label</th>\n      <th>Final_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1179055004553900032_twitter</td>\n      <td>i dont think im getting my baby them white 9 h...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>normal</td>\n      <td>[None]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1179063826874032128_twitter</td>\n      <td>we cannot continue calling ourselves feminists...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>normal</td>\n      <td>[None]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1178793830532956161_twitter</td>\n      <td>nawt yall niggers ignoring me</td>\n      <td>[0, 0, 0, 0, 0]</td>\n      <td>normal</td>\n      <td>[African]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1179088797964763136_twitter</td>\n      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>hatespeech</td>\n      <td>[Asian]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1179085312976445440_twitter</td>\n      <td>this bitch in whataburger eating a burger with...</td>\n      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>hatespeech</td>\n      <td>[Caucasian, Women]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19224</th>\n      <td>9989999_gab</td>\n      <td>if ur still on twitter tell carlton i said his...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, ...</td>\n      <td>offensive</td>\n      <td>[None]</td>\n    </tr>\n    <tr>\n      <th>19225</th>\n      <td>9990225_gab</td>\n      <td>when i first got on here and said i hate trump...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>offensive</td>\n      <td>[African]</td>\n    </tr>\n    <tr>\n      <th>19226</th>\n      <td>9991681_gab</td>\n      <td>was macht der moslem wenn der zion gegen seine...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n      <td>normal</td>\n      <td>[None]</td>\n    </tr>\n    <tr>\n      <th>19227</th>\n      <td>9992513_gab</td>\n      <td>it is awful look at world demographics asians ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...</td>\n      <td>hatespeech</td>\n      <td>[Asian]</td>\n    </tr>\n    <tr>\n      <th>19228</th>\n      <td>9998729_gab</td>\n      <td>the jewish globalist elite have only imported ...</td>\n      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, ...</td>\n      <td>offensive</td>\n      <td>[Islam, Jewish, African]</td>\n    </tr>\n  </tbody>\n</table>\n<p>19229 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"rationales =list(df['rationales'])","metadata":{"execution":{"iopub.status.busy":"2024-07-07T14:51:30.494429Z","iopub.execute_input":"2024-07-07T14:51:30.495217Z","iopub.status.idle":"2024-07-07T14:51:30.505937Z","shell.execute_reply.started":"2024-07-07T14:51:30.495181Z","shell.execute_reply":"2024-07-07T14:51:30.504752Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## MLM Training ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, RandomSampler\nfrom transformers import BertTokenizer, BertForMaskedLM, AdamW\nfrom transformers import get_scheduler\n\n# Load tokenizer and model\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased',truncate=True)\nmodel = BertForMaskedLM.from_pretrained('bert-base-uncased')\n\n\ndevice = torch.device(\"cuda\")\nmodel.to(device)\n\nclass TextDataset(Dataset):\n    def __init__(self, texts, rationales, tokenizer, max_len=180, mask_percentage=0.15):\n        self.tokenizer = tokenizer\n        self.texts = texts\n        self.rationales = rationales\n        self.max_len = max_len\n        self.mask_percentage = mask_percentage\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        rationale = self.rationales[idx]\n\n        # Tokenization\n        tokens = tokenizer.tokenize(text)\n        input_ids = tokenizer.encode(tokens, add_special_tokens=True)\n\n        # Apply rationale to each subword\n        rationale_extended = []\n        for word, rat in zip(text.split(), rationale):\n            subwords = tokenizer.tokenize(word)\n            rationale_extended.extend([rat] * len(subwords))\n        rationale_extended = [0] + rationale_extended + [0]  # Adjust for [CLS] and [SEP]\n\n        # Masking\n        mask_positions = [i for i, r in enumerate(rationale_extended) if r == 1]\n        num_to_mask = int(len(mask_positions) * self.mask_percentage)\n        selected_masks = np.random.choice(mask_positions, num_to_mask, replace=False)\n        labels = input_ids[:]  # Copy input_ids to labels\n\n        # print(\"Before padding:\")\n        # print(\"Input IDs:\", input_ids)\n        # print(\"Labels:\", labels)\n        # print(\"Mask positions:\", selected_masks)\n\n        for i in selected_masks:\n            input_ids[i] = tokenizer.mask_token_id\n\n        # Padding\n        padding_length = self.max_len - len(input_ids)\n        if padding_length > 0:  # Pad if sequence is shorter than max_len\n            input_ids.extend([tokenizer.pad_token_id] * padding_length)\n            labels.extend([-100] * padding_length)\n\n        return torch.tensor(input_ids), torch.tensor(labels)\n\n# Parameters\ntexts = input_data\n# rationales = list(df['rationales'])\n# rationales\nmask_percentage = 0.5# 50% of the tokens marked by 1 in the rationale will be masked\n\n# Dataset and DataLoader\ndataset = TextDataset(texts, rationales, tokenizer, max_len=180, mask_percentage=mask_percentage)\ndataloader = DataLoader(dataset, batch_size=16, sampler=RandomSampler(dataset))\n\n# Optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=2e-5)\nnum_epochs = 3\nnum_training_steps = num_epochs * len(dataloader)\nlr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n\n# Training loop\nmodel.train()\nfor epoch in range(num_epochs):\n    print(epoch)\n    for batch in dataloader:\n        inputs, labels = batch[0].to(device), batch[1].to(device)\n        model.zero_grad()\n        outputs = model(inputs, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        #print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n\n# Save the fine-tuned model\nmodel.save_pretrained('./fine_tuned_bert')\n\n# Evaluation\nmodel.eval()\ntotal_accuracy = 0\nnum_batches = 0\n\nfor batch in dataloader:\n    inputs, labels = batch[0].to(device), batch[1].to(device)\n    with torch.no_grad():\n        outputs = model(inputs, labels=labels)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n\n        # Exclude [CLS], [SEP], and [PAD] from accuracy calculation\n        mask = (labels != -100) & (inputs != tokenizer.cls_token_id) & (inputs != tokenizer.sep_token_id)\n        correct = (predictions == labels) & mask\n        accuracy = correct.sum().item() / mask.sum().item() if mask.sum().item() > 0 else 0\n\n        total_accuracy += accuracy\n        num_batches += 1\n\naverage_accuracy = total_accuracy / num_batches\nprint(f\"Average Accuracy: {average_accuracy}\")\n\n# Qualitative Analysis\n# inputs, labels = next(iter(dataloader))\n# with torch.no_grad():\n#     outputs = model(inputs)\n#     predictions = torch.argmax(outputs.logits, dim=-1)\n\n#     # Filter tokens for display\n#     input_tokens = tokenizer.convert_ids_to_tokens(inputs[0])\n#     prediction_tokens = [pred if (lab != -100 and inp not in [tokenizer.cls_token_id, tokenizer.sep_token_id]) else '[IGNORED]' for pred, lab, inp in zip(tokenizer.convert_ids_to_tokens(predictions[0]), labels[0], inputs[0])]\n\n#     print(\"Input Tokens:      \", input_tokens)\n#     print(\"Predicted Tokens:  \", prediction_tokens)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":537},"id":"YUdJnQTkCCVX","outputId":"f2017749-4bde-4866-8c52-3f2b3458d571","execution":{"iopub.status.busy":"2024-07-07T15:01:13.333426Z","iopub.execute_input":"2024-07-07T15:01:13.333814Z","iopub.status.idle":"2024-07-07T15:29:15.868485Z","shell.execute_reply.started":"2024-07-07T15:01:13.333786Z","shell.execute_reply":"2024-07-07T15:29:15.867456Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:588: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"0\n1\n2\nAverage Accuracy: 0.9788632084692769\n","output_type":"stream"}]},{"cell_type":"code","source":"!zip -r bert_mlm_model.zip /kaggle/working/fine_tuned_bert","metadata":{"id":"r4W7ZMajrC39","outputId":"07480f7b-8c74-46e3-acd3-b3dded35ac36","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-07T15:33:50.018595Z","iopub.execute_input":"2024-07-07T15:33:50.018993Z","iopub.status.idle":"2024-07-07T15:34:14.395276Z","shell.execute_reply.started":"2024-07-07T15:33:50.018960Z","shell.execute_reply":"2024-07-07T15:34:14.394269Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/fine_tuned_bert/ (stored 0%)\n  adding: kaggle/working/fine_tuned_bert/generation_config.json (deflated 8%)\n  adding: kaggle/working/fine_tuned_bert/model.safetensors (deflated 7%)\n  adding: kaggle/working/fine_tuned_bert/config.json (deflated 47%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Classification Bert","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\n# Ensure you have the necessary packages installed:\n# pip install transformers torch sklearn\n\n# Example labels and input data\nlabels = list(df['label'])\ninput_data = list(df['input_text'])\n\n# Label Encoding\nlabel_encoder = LabelEncoder()\nencoded_labels = label_encoder.fit_transform(labels)\n\n# Train-test split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(input_data, encoded_labels, stratify=encoded_labels, test_size=0.2, random_state=42)\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('/kaggle/working/fine_tuned_bert', num_labels=len(np.unique(train_labels)))\n\n\n# Tokenization and input formatting\ndef tokenize_and_format(texts, labels):\n    encodings = tokenizer(texts, padding=True, truncation=True, max_length=180, return_tensors=\"pt\")\n    dataset = TensorDataset(encodings['input_ids'], encodings['attention_mask'], torch.tensor(labels))\n    return dataset\n\ntrain_dataset = tokenize_and_format(train_texts, train_labels)\nval_dataset = tokenize_and_format(val_texts, val_labels)\n\n# DataLoader setup\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\")\nmodel.to(device)\n\n# Optimizer and Loss Function\noptimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\nloss_fn = torch.nn.CrossEntropyLoss()\n\n# Training loop\ndef train(epoch):\n    model.train()\n    total_loss = 0\n    for batch in train_loader:\n        batch = tuple(item for item in batch)\n        inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device), 'labels': batch[2].to(device)}\n        optimizer.zero_grad()\n        outputs = model(**inputs)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    average_loss = total_loss / len(train_loader)\n    print(f'Epoch {epoch}, Training loss: {average_loss}')\n\n# Evaluation function\ndef evaluate(loader):\n    model.eval()\n    predictions, true_labels = [], []\n    with torch.no_grad():\n        for batch in loader:\n            batch = tuple(item for item in batch)\n            inputs = {'input_ids': batch[0].to(device), 'attention_mask': batch[1].to(device)}\n            labels = batch[2]\n            outputs = model(**inputs)\n            logits = outputs.logits\n            predicted_labels = torch.argmax(logits, dim=1)\n            predictions.extend(predicted_labels.cpu().numpy())\n            true_labels.extend(labels.cpu().numpy())\n    report = classification_report(true_labels, predictions, target_names=label_encoder.classes_, digits=3)\n    print(report)\n\n# Train the model\nfor epoch in range(1, 3):  # Number of epochs\n    print(epoch)\n    train(epoch)\n    evaluate(val_loader)\n\n# Evaluate the model\nevaluate(val_loader)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8e_qftb0DPfX","outputId":"e2bafad4-ea73-4f8a-e32b-f31d335d74f5","execution":{"iopub.status.busy":"2024-07-07T15:35:33.069443Z","iopub.execute_input":"2024-07-07T15:35:33.070347Z","iopub.status.idle":"2024-07-07T15:44:55.489912Z","shell.execute_reply.started":"2024-07-07T15:35:33.070310Z","shell.execute_reply":"2024-07-07T15:44:55.488957Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /kaggle/working/fine_tuned_bert and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"1\nEpoch 1, Training loss: 0.7793874450632043\n              precision    recall  f1-score   support\n\n  hatespeech      0.731     0.848     0.785      1187\n      normal      0.760     0.756     0.758      1563\n   offensive      0.596     0.496     0.542      1096\n\n    accuracy                          0.711      3846\n   macro avg      0.696     0.700     0.695      3846\nweighted avg      0.704     0.711     0.705      3846\n\n2\nEpoch 2, Training loss: 0.6218120709154561\n              precision    recall  f1-score   support\n\n  hatespeech      0.735     0.848     0.787      1187\n      normal      0.725     0.809     0.765      1563\n   offensive      0.631     0.422     0.505      1096\n\n    accuracy                          0.711      3846\n   macro avg      0.697     0.693     0.686      3846\nweighted avg      0.701     0.711     0.698      3846\n\n              precision    recall  f1-score   support\n\n  hatespeech      0.735     0.848     0.787      1187\n      normal      0.725     0.809     0.765      1563\n   offensive      0.631     0.422     0.505      1096\n\n    accuracy                          0.711      3846\n   macro avg      0.697     0.693     0.686      3846\nweighted avg      0.701     0.711     0.698      3846\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom sklearn.metrics import roc_auc_score, classification_report\n\n# Evaluation function with AUROC and detailed classification report\ndef evaluate(loader):\n    model.eval()\n    all_logits = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in loader:\n            batch = tuple(item.to(device) for item in batch)\n            inputs = {'input_ids': batch[0], 'attention_mask': batch[1]}\n            labels = batch[2]\n            outputs = model(**inputs)\n            logits = outputs.logits\n            all_logits.extend(logits.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calculate probabilities\n    probabilities = F.softmax(torch.tensor(all_logits), dim=1).numpy()\n\n    # Calculate AUROC for each class (assuming binary or multi-class classification)\n    if probabilities.shape[1] == 2:  # Binary classification\n        auroc = roc_auc_score(all_labels, probabilities[:, 1])\n    else:  # Multi-class classification\n        auroc = roc_auc_score(all_labels, probabilities, multi_class=\"ovr\")\n    print(f\"AUROC: {auroc}\")\n\n    # Print the classification report with 3 decimal places\n    report = classification_report(all_labels, np.argmax(probabilities, axis=1), target_names=label_encoder.classes_, digits=3)\n    print(report)\n\n# Note: Make sure to call evaluate(val_loader) to see the results during or after training.\nevaluate(val_loader)","metadata":{"id":"SI7rwDpRxrk-","outputId":"e8c2f680-e2c0-4bb4-961c-4dbac8b5fb45","colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-07-07T15:44:55.491740Z","iopub.execute_input":"2024-07-07T15:44:55.492018Z","iopub.status.idle":"2024-07-07T15:45:05.934776Z","shell.execute_reply.started":"2024-07-07T15:44:55.491994Z","shell.execute_reply":"2024-07-07T15:45:05.933914Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"AUROC: 0.870181520146165\n              precision    recall  f1-score   support\n\n  hatespeech      0.735     0.848     0.787      1187\n      normal      0.725     0.809     0.765      1563\n   offensive      0.631     0.422     0.505      1096\n\n    accuracy                          0.711      3846\n   macro avg      0.697     0.693     0.686      3846\nweighted avg      0.701     0.711     0.698      3846\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_34/3765978545.py:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /usr/local/src/pytorch/torch/csrc/utils/tensor_new.cpp:261.)\n  probabilities = F.softmax(torch.tensor(all_logits), dim=1).numpy()\n","output_type":"stream"}]},{"cell_type":"code","source":"model.save_pretrained('./final_fine_tuned_bert')\n","metadata":{"id":"mgWubqDC8jS8","execution":{"iopub.status.busy":"2024-07-07T15:45:05.936729Z","iopub.execute_input":"2024-07-07T15:45:05.937015Z","iopub.status.idle":"2024-07-07T15:45:06.696014Z","shell.execute_reply.started":"2024-07-07T15:45:05.936989Z","shell.execute_reply":"2024-07-07T15:45:06.695197Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"!zip -r bert_cf_model.zip /kaggle/working/final_fine_tuned_bert","metadata":{"execution":{"iopub.status.busy":"2024-07-07T15:45:48.112655Z","iopub.execute_input":"2024-07-07T15:45:48.113266Z","iopub.status.idle":"2024-07-07T15:46:12.095715Z","shell.execute_reply.started":"2024-07-07T15:45:48.113238Z","shell.execute_reply":"2024-07-07T15:46:12.094713Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/final_fine_tuned_bert/ (stored 0%)\n  adding: kaggle/working/final_fine_tuned_bert/model.safetensors (deflated 7%)\n  adding: kaggle/working/final_fine_tuned_bert/config.json (deflated 51%)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}